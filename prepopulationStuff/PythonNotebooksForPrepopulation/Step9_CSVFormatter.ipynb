{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# The directory containing your folders with JSON files\n",
    "root_directory = 'C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\track_information'\n",
    "\n",
    "# The path for the output CSV file\n",
    "csv_file_path = 'tracks_data.csv'\n",
    "\n",
    "# Current date for 'Date Added To DB' and 'Date Last Modified' columns in the YYYY-MM-DD format\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Template for CSV rows with the updated header titles\n",
    "csv_columns = [\n",
    "    'id', 'song_spotify_id', 'song_title', 'song_duration', 'song_album_type', \n",
    "    'song_album_id', 'song_explicit', 'song_popularity', 'song_preview_url', \n",
    "    'song_track_features_added', 'song_acousticness', 'song_danceability', 'song_energy', \n",
    "    'song_instrumentalness', 'song_liveness', 'song_loudness', 'song_speechiness', \n",
    "    'song_tempo', 'song_valence', 'song_key', 'song_time_signature', 'song_date_added_to_db', \n",
    "    'song_date_last_modified'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store rows for the CSV\n",
    "csv_rows = []\n",
    "\n",
    "def process_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        for track in data.get('tracks', []):\n",
    "            # Skip processing if the track is None\n",
    "            if track is None:\n",
    "                continue\n",
    "\n",
    "            row = {\n",
    "                'id': -1,  # This will be updated later with the actual ID\n",
    "                'song_spotify_id': track['id'],\n",
    "                'song_title': track['name'],\n",
    "                'song_duration': track['duration_ms'],\n",
    "                'song_album_type': track['album']['album_type'].upper(),\n",
    "                'song_album_id': track['album']['id'],\n",
    "                'song_explicit': track['explicit'],\n",
    "                'song_popularity': track['popularity'],\n",
    "                'song_preview_url': track.get('preview_url', ''),\n",
    "                'song_track_features_added': False,\n",
    "                'song_acousticness': -1,\n",
    "                'song_danceability': -1,\n",
    "                'song_energy': -1,\n",
    "                'song_instrumentalness': -1,\n",
    "                'song_liveness': -1,\n",
    "                'song_loudness': -1,\n",
    "                'song_speechiness': -1,\n",
    "                'song_tempo': -1,\n",
    "                'song_valence': -1,\n",
    "                'song_key': -1,\n",
    "                'song_time_signature': -1,\n",
    "                'song_date_added_to_db': current_date,\n",
    "                'song_date_last_modified': current_date\n",
    "            }\n",
    "            csv_rows.append(row)\n",
    "\n",
    "# Iterate over each subfolder and JSON file in the directory\n",
    "for subdir, dirs, files in os.walk(root_directory):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.json'):\n",
    "            print(f\"Processing {filename}...\")\n",
    "            process_json_file(os.path.join(subdir, filename))\n",
    "\n",
    "# Write the CSV file\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=csv_columns, delimiter=';')\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Update each row with its ID before writing\n",
    "    for i, row in enumerate(csv_rows, start=1):\n",
    "        row['id'] = i\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file has been successfully created at {csv_file_path} with {len(csv_rows)} tracks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the root directory containing your JSON files\n",
    "root_directory = 'C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\ALBUMS'\n",
    "\n",
    "# Define the output CSV file path\n",
    "csv_file_path = 'album_data.csv'\n",
    "\n",
    "# Current date for 'Date Added To DB' and 'Date Last Modified' columns\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# CSV column headers\n",
    "csv_columns = [\n",
    "    'id', 'album_spotify_id', 'album_name', 'album_cover_art', 'album_release_date',\n",
    "    'release_date_precision', 'album_popularity', 'album_type', 'spotify_album_upc',\n",
    "    'spotify_album_ean', 'spotify_album_isrc', 'date_added_to_db', 'date_last_modified',\n",
    "    'musicbrainz_metadata_added', 'musicbrainz_id'\n",
    "]\n",
    "\n",
    "# Initialize a list to hold album data\n",
    "albums_data = []\n",
    "\n",
    "# Function to process each JSON file\n",
    "def process_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        for album in data.get('albums', []):\n",
    "            # Extract the required information, with checks for nullable fields\n",
    "            album_data = {\n",
    "                'id': -1,  # Placeholder, will be updated later\n",
    "                'album_spotify_id': album['id'],\n",
    "                'album_name': album['name'],\n",
    "                'album_cover_art': album['images'][0]['url'] if album.get('images') else '',\n",
    "                'album_release_date': album['release_date'],\n",
    "                'release_date_precision': album['release_date_precision'],\n",
    "                'album_popularity': album['popularity'],\n",
    "                'album_type': album['album_type'],\n",
    "                'spotify_album_upc': album['external_ids'].get('upc', '') if album.get('external_ids') else '',\n",
    "                'spotify_album_ean': album['external_ids'].get('ean', '') if album.get('external_ids') else '',\n",
    "                'spotify_album_isrc': album['external_ids'].get('isrc', '') if album.get('external_ids') else '',\n",
    "                'date_added_to_db': current_date,\n",
    "                'date_last_modified': current_date,\n",
    "                'musicbrainz_metadata_added': False,  # Placeholder\n",
    "                'musicbrainz_id': ''  # Placeholder\n",
    "            }\n",
    "            albums_data.append(album_data)\n",
    "\n",
    "# Process each JSON file in the directory and subdirectories\n",
    "for subdir, dirs, files in os.walk(root_directory):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.json'):\n",
    "            process_json_file(os.path.join(subdir, filename))\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=csv_columns, delimiter=';')\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Update each row with its actual ID before writing\n",
    "    for i, album_data in enumerate(albums_data, start=1):\n",
    "        album_data['id'] = i\n",
    "        writer.writerow(album_data)\n",
    "\n",
    "print(f\"CSV file has been successfully created at {csv_file_path} with {len(albums_data)} albums.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the dtypes for the IDs to be strings when reading the CSVs\n",
    "dtype_dict = {'id': str, 'song_album_id': str, 'album_spotify_id': str}\n",
    "tracks_df = pd.read_csv('C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\tracks_data.csv', delimiter=';', dtype=dtype_dict)\n",
    "albums_df = pd.read_csv('C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\album_data.csv', delimiter=';', dtype=dtype_dict)\n",
    "\n",
    "# Create a dictionary mapping from album_spotify_id to id from albums_df\n",
    "# Ensure the 'id' column in albums_df is converted to integer if it's not NaN\n",
    "album_id_map = albums_df.dropna(subset=['id']).set_index('album_spotify_id')['id'].astype(int).to_dict()\n",
    "\n",
    "# Map the song_album_id in tracks_df using the album_id_map to get the album id\n",
    "tracks_df['album_id'] = tracks_df['song_album_id'].map(album_id_map)\n",
    "\n",
    "# Convert the new album_id column to integers, NaNs will be converted to a float with a .0\n",
    "tracks_df['album_id'] = tracks_df['album_id'].fillna(-1).astype(int)\n",
    "\n",
    "# Replace -1 back to NaN if you want to keep NaN values\n",
    "tracks_df['album_id'].replace(-1, pd.NA, inplace=True)\n",
    "\n",
    "# Save the updated tracks DataFrame to a new CSV file\n",
    "tracks_df.to_csv('path_to_updated_tracks.csv', index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Read the albums and artists CSVs into DataFrames\n",
    "albums_df = pd.read_csv('C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\album_data.csv', delimiter=';', dtype={'id': str, 'album_spotify_id': str})\n",
    "artists_df = pd.read_csv('C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\artists_data.csv', delimiter=';', dtype={'id': str, 'artist_spotify_id': str})\n",
    "\n",
    "# Dictionary to map Spotify album ID to CSV album ID\n",
    "album_id_map = albums_df.set_index('album_spotify_id')['id'].to_dict()\n",
    "\n",
    "# Dictionary to map Spotify artist ID to CSV artist ID\n",
    "artist_id_map = artists_df.set_index('artist_spotify_id')['id'].to_dict()\n",
    "\n",
    "# Initialize a list to hold the artist-album mappings\n",
    "artist_album_mapping = []\n",
    "\n",
    "# Assuming 'path_to_json_folder' is the folder containing all the JSON subfolders\n",
    "for root, dirs, files in os.walk('C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\ALBUMS'):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            with open(os.path.join(root, file), 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                for album in data['albums']:\n",
    "                    album_id = album_id_map.get(album['id'])\n",
    "                    if album_id:\n",
    "                        for artist in album['artists']:\n",
    "                            artist_id = artist_id_map.get(artist['id'])\n",
    "                            if artist_id:\n",
    "                                artist_album_mapping.append({'artistID': artist_id, 'albumID': album_id})\n",
    "\n",
    "# Create a DataFrame from the artist-album mappings\n",
    "artist_album_df = pd.DataFrame(artist_album_mapping)\n",
    "\n",
    "# Remove duplicates if there are any\n",
    "artist_album_df = artist_album_df.drop_duplicates()\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "artist_album_df.to_csv('artist_album_mappings.csv', index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Read the albums and artists CSVs into DataFrames\n",
    "albums_df = pd.read_csv('C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\album_data.csv', delimiter=';', dtype={'id': str, 'album_spotify_id': str})\n",
    "artists_df = pd.read_csv('C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\artists_data.csv', delimiter=';', dtype={'id': str, 'artist_spotify_id': str})\n",
    "\n",
    "# Dictionary to map Spotify album ID to CSV album ID\n",
    "album_id_map = albums_df.set_index('album_spotify_id')['id'].to_dict()\n",
    "\n",
    "# Dictionary to map Spotify artist ID to CSV artist ID\n",
    "artist_id_map = artists_df.set_index('artist_spotify_id')['id'].to_dict()\n",
    "\n",
    "# Initialize a list to hold the artist-album mappings\n",
    "artist_album_mapping = []\n",
    "\n",
    "# List to hold artist Spotify IDs where CSV artist ID was not found\n",
    "missing_artist_ids = []\n",
    "\n",
    "# Assuming 'path_to_json_folder' is the folder containing all the JSON subfolders\n",
    "for root, dirs, files in os.walk('C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\ALBUMS'):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            with open(os.path.join(root, file), 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                for album in data['albums']:\n",
    "                    album_id = album_id_map.get(album['id'])\n",
    "                    if album_id:\n",
    "                        for artist in album['artists']:\n",
    "                            artist_spotify_id = artist['id']\n",
    "                            artist_id = artist_id_map.get(artist_spotify_id)\n",
    "                            if artist_id:\n",
    "                                artist_album_mapping.append({'artistID': artist_id, 'albumID': album_id})\n",
    "                            else:\n",
    "                                missing_artist_ids.append(artist_spotify_id)\n",
    "\n",
    "# Print the list of artist Spotify IDs where the CSV artist ID was not found\n",
    "print(\"List of artist Spotify IDs where the CSV artist ID was not found:\")\n",
    "for artist_id in missing_artist_ids:\n",
    "    print(artist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "missing_artist_ids_df = pd.DataFrame(missing_artist_ids, columns=['missing_artist_spotify_id'])\n",
    "\n",
    "# Define the file path where you want to save the CSV\n",
    "file_path = 'missing_artist_ids.csv'  # You can specify your own path\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "missing_artist_ids_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f'The missing artist IDs have been saved to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2TENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
