{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def find_json_files(directory):\n",
    "    json_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                json_files.append(os.path.join(root, file))\n",
    "    return json_files\n",
    "\n",
    "def extract_track_ids(json_files):\n",
    "    track_ids = []\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            albums = data.get('albums', [])\n",
    "            for album in albums:\n",
    "                tracks = album.get('tracks', {}).get('items', [])\n",
    "                for track in tracks:\n",
    "                    track_ids.append(track.get('id'))\n",
    "    return track_ids\n",
    "\n",
    "# Specify the folder path here\n",
    "folder_path = 'C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\ALBUMS'\n",
    "\n",
    "# Find all JSON files within the folder and its subfolders\n",
    "json_files = find_json_files(folder_path)\n",
    "\n",
    "# Extract all track IDs from these JSON files\n",
    "track_ids = extract_track_ids(json_files)\n",
    "\n",
    "unique_track_ids = list(set(track_ids))\n",
    "\n",
    "# Save unique track IDs to a file\n",
    "with open('unique_track_ids.txt', 'w') as f:\n",
    "    for track_id in unique_track_ids:\n",
    "        f.write(f\"{track_id}\\n\")\n",
    "\n",
    "print(\"Unique track IDs have been saved to unique_track_ids.txt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "def load_track_ids(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read().splitlines()  # Assuming each track ID is on a new line\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "        return []\n",
    "\n",
    "def get_tracks_info(track_ids, access_token, market='US'):\n",
    "    url = 'https://api.spotify.com/v1/tracks'\n",
    "    headers = {'Authorization': f'Bearer {access_token}'}\n",
    "    params = {'ids': ','.join(track_ids), 'market': market}\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to retrieve tracks information. Status code: {response.status_code}, Response: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Replace with your actual Spotify access token\n",
    "access_token = 'BQAuDuCoQIDmqoQshBaDH7Q3XrVRMRPndhKrkrToNFoQOamhT0I7OsUkkQFtKjz7xvSjeXIFggllEvbXA-98kMgcNR8g_eI_jj2UNsGLlWSnBQSNenWbuVRCDmfeqG_9_55CFsrStBfSYpU5QqbmzjGo_9EzbDtbafjd6XEFxaPUxPjInWFLx5LkTeRa9yjVaiW33BOvtTlwFe5v-6y82wmcsPuumEK749ytm6EYhznuvQGS8Eklr6uFPjVOPky-UmYSDCc5_Ei-OV9ZxoUaY_aodN6yo4M2YEb2pC10'\n",
    "# The path to your file containing track IDs\n",
    "track_ids_file_path = 'TRACK_IDs_TO_SCRAPE.txt'\n",
    "# The directory where the fetched track information will be saved\n",
    "output_directory = 'track_information'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Load the track IDs\n",
    "track_ids = load_track_ids(track_ids_file_path)\n",
    "\n",
    "# Process the list in chunks of 50 IDs at a time (Spotify allows up to 100, but 50 is chosen here for demonstration)\n",
    "for i in range(0, len(track_ids), 50):\n",
    "    chunk = track_ids[i:i+50]\n",
    "    tracks_info = get_tracks_info(chunk, access_token)\n",
    "    if tracks_info:\n",
    "        # Consider timestamp or some unique attribute for filename uniqueness if required\n",
    "        timestamp = int(time.time())\n",
    "        with open(f'{output_directory}/tracks_info_{i}-{i+len(chunk)}_{timestamp}.json', 'w') as output_file:\n",
    "            json.dump(tracks_info, output_file)\n",
    "\n",
    "print(\"Tracks information has been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "contributors_df = pd.read_csv('C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\WORKING\\\\contributors_normalized_onlyMatchedArtists.csv')\n",
    "artists_df = pd.read_csv('C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\FINISHED\\\\NEWEST\\\\\\PRODFILES\\\\artists_table.csv', sep=';')\n",
    "artist_album_mapping_df = pd.read_csv('C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\FINISHED\\\\NEWEST\\\\PRODFILES\\\\artist_album_mapping.csv', sep=';')\n",
    "track_data_df = pd.read_csv('C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\SCRAPED_DATA\\\\FINISHED\\\\NEWEST\\\\tracks_data_full.csv', sep=';')\n",
    "\n",
    "# Step 1: Merge artists with their albums\n",
    "artists_with_albums = pd.merge(artists_df, artist_album_mapping_df, left_on='id', right_on='artistID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Merge the above with track data on albumID\n",
    "artist_tracks = pd.merge(artists_with_albums, track_data_df, left_on='albumID', right_on='album_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributors_dict = contributors_df.groupby('artist_mbid')['recording_mbid'].apply(set).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2TENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
