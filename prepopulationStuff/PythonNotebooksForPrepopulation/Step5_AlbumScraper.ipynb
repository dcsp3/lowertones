{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script gets all the unique album IDs\n",
    "import os\n",
    "import json\n",
    "\n",
    "folder_path = 'C:\\\\Users\\\\Music\\\\Desktop\\\\PROJECTS\\\\Spotify Project\\\\artist_albums\\\\dak'\n",
    "unique_ids = set() \n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.json'):  \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            for item in data:\n",
    "                unique_ids.add(item['id']) \n",
    "\n",
    "output_file_path = os.path.join(folder_path, 'unique_ids.txt')\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for id in unique_ids:\n",
    "        output_file.write(id + '\\n')\n",
    "\n",
    "print(f\"Unique IDs have been written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script merges the album IDs from the smaller lists, removing duplicates\n",
    "def load_list_from_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Reads each line into a list, stripping newline characters\n",
    "            return [line.strip() for line in file]\n",
    "    except FileNotFoundError:\n",
    "        return []\n",
    "\n",
    "file_path1 = 'dak_unique_ids.txt'\n",
    "file_path2 = 'rory_unique_ids.txt'\n",
    "file_path3 = 'will_unique_ids.txt'\n",
    "list1 = load_list_from_file(file_path1)\n",
    "list2 = load_list_from_file(file_path2)\n",
    "list3 = load_list_from_file(file_path3)\n",
    "merged_list = list(set(list1 + list2 + list3))\n",
    "output_file_path = 'merged_artist_ids_list.txt'\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for id in merged_list:\n",
    "        output_file.write(id + '\\n') \n",
    "\n",
    "print(merged_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script calls the Spotify API to get the album details for each album ID in batches of 20\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "def load_album_ids(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "        return []\n",
    "\n",
    "def get_albums_info(album_ids, access_token, market='US'):\n",
    "    url = 'https://api.spotify.com/v1/albums'\n",
    "    headers = {'Authorization': f'Bearer {access_token}'}\n",
    "    params = {'ids': ','.join(album_ids), 'market': market}\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(response.headers)\n",
    "        print(f\"Failed to retrieve albums information. Status code: {response.status_code}, Response: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Your Spotify access token and file paths\n",
    "access_token = 'BQBwbcsu_xDB_--wEKxV6fhQsASgvhYmx7tQIwajQlisM8sBuRMffAFK1-so7TOy3IXwk_OJsdcqlMU-cYFPW74-9DEl4BGi2JqlgytuP2GEaR2Kv_RP9uAZOnQBOXrxEjNKcaX7pPfmdbe_qmO6ZAlC8qtRW7g8ZuYbYUAx1XUVZUS529AyFe3LcU9c2QJC0eVcmJc7fVE07L5GbFpe6DG45WEkZvUgbpQ4boJFv0sGjub2xLXVtm9REvShQnY_9dd0s7vZNdUSOW-73cqM78sBh12jsSaCsN0P6IiD'  # Replace with your actual Spotify access token\n",
    "album_ids_file_path = 'merged_artist_ids_list.txt'  # The path to your file containing album IDs\n",
    "output_directory = 'album_information'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Load the album IDs\n",
    "album_ids = load_album_ids(album_ids_file_path)\n",
    "\n",
    "# Process the list in chunks of 20 IDs at a time\n",
    "for i in range(0, len(album_ids), 20):\n",
    "    chunk = album_ids[i:i+20]\n",
    "    albums_info = get_albums_info(chunk, access_token)\n",
    "    if albums_info:\n",
    "        # Consider timestamp or some unique attribute for filename uniqueness if required\n",
    "        timestamp = int(time.time())\n",
    "        with open(f'{output_directory}/albums_info_{i}-{i+len(chunk)}_{timestamp}.json', 'w') as output_file:\n",
    "            json.dump(albums_info, output_file)\n",
    "\n",
    "print(\"Albums information has been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2TENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
